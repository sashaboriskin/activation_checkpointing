[project]
name = "activation-checkpointing"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"

dependencies = [
    "datasets>=4.2.0",
    "flash-attn==2.8.3",
    "pytest>=8.4.2",
    "tensorboard>=2.20.0",
    "torch==2.8.0",
    "torch-tb-profiler>=0.4.3",
    "transformers>=4.57.1",
]

[tool.uv.extra-build-dependencies]
flash-attn = [{ requirement = "torch", match-runtime = true }]

[tool.uv.extra-build-variables]
flash-attn = { FLASH_ATTENTION_SKIP_CUDA_BUILD = "TRUE" }
